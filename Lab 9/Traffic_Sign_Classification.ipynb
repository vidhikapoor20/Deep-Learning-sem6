{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Deep Learning for Traffic Sign Classification Full.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKmFmyaGunc7"
      },
      "source": [
        "# TASK #2: MOUNT DRIVE AND IMPORT LIBRARIES/DATASETS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4OdH814kOII"
      },
      "source": [
        "- In this case study, we want to classify images of traffic signs using deep Convolutional Neural Networks (CNNs).\n",
        "- The dataset consists of 43 different classes of images. \n",
        "- Classes are as listed below: \n",
        "  - 0 = Speed limit (20km/h) \n",
        "  - 1 = Speed limit (30km/h)\n",
        "  - 2 = Speed limit (50km/h) \n",
        "  - 3 = Speed limit (60km/h)\n",
        "  - 4 = Speed limit (70km/h) \n",
        "  - 5 = Speed limit (80km/h)\n",
        "  - 6 = End of speed limit (80km/h)\n",
        "  - 7 = Speed limit (100km/h)\n",
        "  - 8 = Speed limit (120km/h)\n",
        "  - 9 = No passing\n",
        "  - 10 = No passing for vehicles over 3.5 metric tons\n",
        "  - 11 = Right-of-way at the next intersection\n",
        "  - 12 = Priority road\n",
        "  - 13 = Yield\n",
        "  - 14 = Stop\n",
        "  - 15 = No vehicles\n",
        "  - 16 = Vehicles over 3.5 metric tons prohibited\n",
        "  - 17 = No entry\n",
        "  - 18 = General caution\n",
        "  - 19 = Dangerous curve to the left\n",
        "  - 20 = Dangerous curve to the right\n",
        "  - 21 = Double curve\n",
        "  - 22 = Bumpy road\n",
        "  - 23 = Slippery road\n",
        "  - 24 = Road narrows on the right\n",
        "  - 25 = Road work\n",
        "  - 26 = Traffic signals\n",
        "  - 27 = Pedestrians\n",
        "  - 28 = Children crossing \n",
        "  - 29 = Bicycles crossing\n",
        "  - 30 = Beware of ice/snow\n",
        "  - 31 = Wild animals crossing\n",
        "  - 32 = End of all speed and passing limits\n",
        "  - 33 = Turn right ahead\n",
        "  - 34 = Turn left ahead\n",
        "  - 35 = Ahead only\n",
        "  - 36 = Go straight or right\n",
        "  - 37 = Go straight or left\n",
        "  - 38 = Keep right\n",
        "  - 39 = Keep left\n",
        "  - 40 = Roundabout mandatory\n",
        "  - 41 = End of no passing\n",
        "  - 42 = End of no passing by vehicles over 3.5 metric tons\n",
        "\n",
        "- Citation\n",
        "J. Stallkamp, M. Schlipsing, J. Salmen, and C. Igel. The German Traffic Sign Recognition Benchmark: A multi-class classification competition. In Proceedings of the IEEE International Joint Conference on Neural Networks, pages 1453â€“1460. 2011. \n",
        "@inproceedings{Stallkamp-IJCNN-2011, author = {Johannes Stallkamp and Marc Schlipsing and Jan Salmen and Christian Igel}, booktitle = {IEEE International Joint Conference on Neural Networks}, title = {The {G}erman {T}raffic {S}ign {R}ecognition {B}enchmark: A multi-class classification competition}, year = {2011}, pages = {1453--1460} }"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AhbU2fAZh0oe"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import pickle\n",
        "import random"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKpz8CSLh5iQ"
      },
      "source": [
        "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1tQ2HkQdxCUpAo4twbqN6mu7FYD7Ry5tq' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1tQ2HkQdxCUpAo4twbqN6mu7FYD7Ry5tq\" -O train.p && rm -rf /tmp/cookies.txt\n",
        "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1zJxB1YzBYuImaHBSxWGN-ZXPDRYN_CTX' -O valid.p\n",
        "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1jZhZpEZkYFaaPPAwfd1cB8e-FK0aoeC0' -O test.p"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUh_5xdjh0or"
      },
      "source": [
        "with open(\"/content/train.p\", mode='rb') as training_data:\n",
        "    train = pickle.load(training_data)\n",
        "with open(\"/content/valid.p\", mode='rb') as validation_data:\n",
        "    valid = pickle.load(validation_data)\n",
        "with open(\"/content/test.p\", mode='rb') as testing_data:\n",
        "    test = pickle.load(testing_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-uEFeTF3rPl0"
      },
      "source": [
        "X_train, y_train = train['features'], train['labels']\n",
        "X_validation, y_validation = valid['features'], valid['labels']\n",
        "X_test, y_test = test['features'], test['labels']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTLHnPTGrRkc"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jLck0QwrSNz"
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LlszUhNNyrl_"
      },
      "source": [
        "# TASK #3: PERFROM IMAGES VISUALIZATION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ronVvCdJsYc5"
      },
      "source": [
        "i = np.random.randint(1, len(X_train))\n",
        "plt.imshow(X_train[i])\n",
        "y_train[i]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZUUvpXsmlwbb"
      },
      "source": [
        "# Let's view more images in a grid format\n",
        "# Define the dimensions of the plot grid \n",
        "W_grid = 5\n",
        "L_grid = 5\n",
        "\n",
        "# fig, axes = plt.subplots(L_grid, W_grid)\n",
        "# subplot return the figure object and axes object\n",
        "# we can use the axes object to plot specific figures at various locations\n",
        "\n",
        "fig, axes = plt.subplots(L_grid, W_grid, figsize = (10,10))\n",
        "\n",
        "axes = axes.ravel() # flaten the 15 x 15 matrix into 225 array\n",
        "\n",
        "n_training = len(X_train) # get the length of the training dataset\n",
        "\n",
        "# Select a random number from 0 to n_training\n",
        "for i in np.arange(0, W_grid * L_grid): # create evenly spaces variables \n",
        "\n",
        "    # Select a random number\n",
        "    index = np.random.randint(0, n_training)\n",
        "    # read and display an image with the selected index    \n",
        "    axes[i].imshow( X_train[index])\n",
        "    axes[i].set_title(y_train[index], fontsize = 15)\n",
        "    axes[i].axis('off')\n",
        "\n",
        "plt.subplots_adjust(hspace=0.4)\n",
        "\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0GmpAjG3GiH"
      },
      "source": [
        "# TASK #4: CONVERT IMAGES TO GRAYSCALE AND PERFORM NORMALIZATION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YI1QcjORsq2G"
      },
      "source": [
        "from sklearn.utils import shuffle\n",
        "X_train, y_train = shuffle(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O39M8bHRjJYz"
      },
      "source": [
        "#Since its an RGB image, so it means that you have add r with g with b and then divide it by 3 to get your desired grayscale image. Its done in this way. If you have an color image like the image shown above and you want to convert it into grayscale using average method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2-GkZo0riel"
      },
      "source": [
        "X_train_gray = np.sum(X_train/3, axis = 3, keepdims = True)\n",
        "X_test_gray = np.sum(X_test/3, axis = 3, keepdims = True)\n",
        "X_validation_gray = np.sum(X_validation/3, axis = 3, keepdims = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2thgGKwricb"
      },
      "source": [
        "X_train_gray.shape\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4yZu7n28riaV"
      },
      "source": [
        "X_test_gray.shape\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PacZ128mh0qV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nar_imirriYX"
      },
      "source": [
        "X_validation_gray.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xRVL8FpriWI"
      },
      "source": [
        "X_train_gray_norm = (X_train_gray - 128)/128\n",
        "X_test_gray_norm = (X_test_gray - 128)/128\n",
        "X_validation_gray_norm = (X_validation_gray - 128)/128"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vep8YTC1riUI"
      },
      "source": [
        "X_train_gray_norm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__hg6A5yrq2c"
      },
      "source": [
        "i = random.randint(1, len(X_train_gray))\n",
        "plt.imshow(X_train_gray[i].squeeze(), cmap = 'gray')\n",
        "plt.figure()\n",
        "plt.imshow(X_train[i])\n",
        "plt.figure()\n",
        "plt.imshow(X_train_gray_norm[i].squeeze(), cmap = 'gray')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idmwovgTh0rJ"
      },
      "source": [
        "# TASK #6: BUILD DEEP CONVOLUTIONAL NEURAL NETWORK MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFsd6rYsr9uW"
      },
      "source": [
        "from tensorflow.keras import datasets, layers, models\n",
        "\n",
        "CNN = models.Sequential()\n",
        "\n",
        "CNN.add(layers.Conv2D(6, (5,5), activation = 'relu', input_shape = (32,32,1)))\n",
        "CNN.add(layers.AveragePooling2D())\n",
        "\n",
        "#CNN.add(layers.Dropout(0.2))\n",
        "\n",
        "CNN.add(layers.Conv2D(16, (5,5), activation = 'relu'))\n",
        "CNN.add(layers.AveragePooling2D())\n",
        "\n",
        "CNN.add(layers.Flatten())\n",
        "\n",
        "CNN.add(layers.Dense(120, activation = 'relu'))\n",
        "\n",
        "CNN.add(layers.Dense(84, activation = 'relu'))\n",
        "\n",
        "CNN.add(layers.Dense(43, activation = 'softmax'))\n",
        "CNN.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wr9IYeR6acWf"
      },
      "source": [
        "# TASK #7: COMPILE AND TRAIN DEEP CNN MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDTDxCwgsBI1"
      },
      "source": [
        "CNN.compile(optimizer = 'Adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3IyLXbdsCyj"
      },
      "source": [
        "history = CNN.fit(X_train_gray_norm,\n",
        "                 y_train, \n",
        "                 batch_size = 500,\n",
        "                 epochs = 5,\n",
        "                 verbose = 1,\n",
        "                 validation_data = (X_validation_gray_norm, y_validation))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-wRQqOeB5Zh5"
      },
      "source": [
        "# TASK #8: ASSESS TRAINED CNN MODEL PERFORMANCE "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RpB2PAd9SE9"
      },
      "source": [
        "score = CNN.evaluate(X_test_gray_norm, y_test)\n",
        "print('Test Accuracy: {}'.format(score[1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FM1WY_Q_sMkL"
      },
      "source": [
        "history.history.keys()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBBJ9WlpsMiH"
      },
      "source": [
        "accuracy = history.history['accuracy']\n",
        "val_accuracy = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8oHEt0OsMf2"
      },
      "source": [
        "epochs = range(len(accuracy))\n",
        "\n",
        "plt.plot(epochs, accuracy, 'bo', label='Training Accuracy')\n",
        "plt.plot(epochs, val_accuracy, 'b', label='Validation Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "liiGj4HdsMa3"
      },
      "source": [
        "plt.plot(epochs, loss, 'ro', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "plt.title('Training and Validation loss')\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKZxo6khsMYv"
      },
      "source": [
        "predicted_classes = CNN.predict_classes(X_test_gray_norm)\n",
        "y_true = y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3knUnry5sMWd"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(y_true, predicted_classes)\n",
        "plt.figure(figsize = (25, 25))\n",
        "sns.heatmap(cm, annot = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3WLTbXkysVdv"
      },
      "source": [
        "L = 5\n",
        "W = 5\n",
        "\n",
        "fig, axes = plt.subplots(L, W, figsize = (12, 12))\n",
        "axes = axes.ravel()\n",
        "\n",
        "for i in np.arange(0, L*W):\n",
        "    axes[i].imshow(X_test[i])\n",
        "    axes[i].set_title('Prediction = {}\\n True = {}'.format(predicted_classes[i], y_true[i]))\n",
        "    axes[i].axis('off')\n",
        "\n",
        "plt.subplots_adjust(wspace = 1)    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rW4v5N7zzwMZ"
      },
      "source": [
        "# CONGRATULATIONS ON FINISHING THE PROJECT!"
      ]
    }
  ]
}