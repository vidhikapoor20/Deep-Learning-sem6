{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Learner_Notebook.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KeHZOb76Eoao"
      },
      "source": [
        "<h2 align=center> Classify Radio Signals from Outer Space with Keras</h2>\n",
        "\n",
        "> Indented block\n",
        "\n",
        "> Indented block\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "<img src=\"https://upscfever.com/datasets/Allen_Telescope.jpg\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AzF3Kx17YjNA"
      },
      "source": [
        "![](Allen_Telescope.jpg)\n",
        "[Allen Telescope Array](https://flickr.com/photos/93452909@N00/5656086917) by [brewbooks](https://www.flickr.com/people/93452909@N00) is licensed under [CC BY 2.0](https://creativecommons.org/licenses/by/2.0/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fB2voc0SFB0W"
      },
      "source": [
        "## Task 1: Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7imLjGkqtuHx"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn import metrics\n",
        "\n",
        "import numpy as np\n",
        "np.random.seed(42)\n",
        "import warnings;warnings.simplefilter('ignore')\n",
        "%matplotlib inline\n",
        "print('Tensorflow version:', tf.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_NCQF1PvZbFp"
      },
      "source": [
        "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=19nuL1JWqCDerQxfh1jrFtYyQsYP3Oq55' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=19nuL1JWqCDerQxfh1jrFtYyQsYP3Oq55\" -O dataset.zip && rm -rf /tmp/cookies.txt\n",
        "!unzip dataset.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8q9a-6AOtuKg"
      },
      "source": [
        "## Task 2: Load and Preprocess SETI Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3J-nEHNHtuK6"
      },
      "source": [
        "train_images = pd.read_csv('dataset/train/images.csv', header=None)\n",
        "train_labels = pd.read_csv('dataset/train/labels.csv', header=None)\n",
        "\n",
        "val_images = pd.read_csv('dataset/validation/images.csv', header=None)\n",
        "val_labels = pd.read_csv('dataset/validation/labels.csv', header=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8IQRiZN4tuNJ"
      },
      "source": [
        "train_images.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJjApp9btuO3"
      },
      "source": [
        "train_labels.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "INLX8oL6tuQW"
      },
      "source": [
        "print(\"Training set shape:\", train_images.shape, train_labels.shape)\n",
        "print(\"Validation set shape:\", val_images.shape, val_labels.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqP50asituR-"
      },
      "source": [
        "x_train = train_images.values.reshape(3200, 64, 128, 1)\n",
        "x_val = val_images.values.reshape(800, 64, 128, 1)\n",
        "\n",
        "y_train = train_labels.values\n",
        "y_val = val_labels.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nYkM8WivtuUn"
      },
      "source": [
        "## Task 3: Plot 2D Spectrograms"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXCfc_nStuU1"
      },
      "source": [
        "plt.figure(0, figsize=(12,12))\n",
        "for i in range(1,4):\n",
        "    plt.subplot(1,3,i)\n",
        "    img = np.squeeze(x_train[np.random.randint(0, x_train.shape[0])])\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.imshow(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3Jh0ReItuVz"
      },
      "source": [
        "plt.imshow(np.squeeze(x_train[3]), cmap=\"gray\");"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Us1zFH16tuYD"
      },
      "source": [
        "## Task 4: Create Training and Validation Data Generators"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egnWmd0Kvfye"
      },
      "source": [
        "?ImageDataGenerator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZpV7zJ_tuYT"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen_train = ImageDataGenerator(horizontal_flip=True)\n",
        "datagen_train.fit(x_train)\n",
        "\n",
        "datagen_val = ImageDataGenerator(horizontal_flip=True)\n",
        "datagen_val.fit(x_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g63zJ2I2tuax"
      },
      "source": [
        "## Task 5: Creating the CNN Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTGak_7Xtua7"
      },
      "source": [
        "from tensorflow.keras.layers import Dense, Input, Dropout,Flatten, Conv2D\n",
        "from tensorflow.keras.layers import BatchNormalization, Activation, MaxPooling2D\n",
        "\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
        "from tensorflow.keras.utils import plot_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SfsSBMQztub2"
      },
      "source": [
        "# Initialising the CNN\n",
        "model = Sequential()\n",
        "\n",
        "# 1st Convolution\n",
        "model.add(Conv2D(32,(5,5), padding='same', input_shape=(64, 128,1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# 2nd Convolution layer\n",
        "model.add(Conv2D(64,(5,5), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# Flattening\n",
        "model.add(Flatten())\n",
        "\n",
        "# Fully connected layer\n",
        "model.add(Dense(1024))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "model.add(Dense(4, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WPxVqNXgtucz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_afiiHMtudl"
      },
      "source": [
        "## Task 6: Learning Rate Scheduling and Compile the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGlRuGD4vrVQ"
      },
      "source": [
        "?tf.keras.optimizers.schedules.ExponentialDecay"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFn3ITJstuds"
      },
      "source": [
        "initial_learning_rate = 0.005\n",
        "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate,\n",
        "    decay_steps=5,\n",
        "    decay_rate=0.96,\n",
        "    staircase=True)\n",
        "\n",
        "optimizer = Adam(learning_rate=lr_schedule)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YsyZB38ttueR"
      },
      "source": [
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45Mz3xSDtue6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aAlOFjnQtufh"
      },
      "source": [
        "## Task 7: Training the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ePHf0qbEtufp"
      },
      "source": [
        "checkpoint = ModelCheckpoint(\"model_weights.h5\", monitor='val_loss',\n",
        "                             save_weights_only=True, mode='min', verbose=0)\n",
        "callbacks = [checkpoint]#, reduce_lr]\n",
        "batch_size = 32\n",
        "history = model.fit(\n",
        "    datagen_train.flow(x_train, y_train, batch_size=batch_size, shuffle=True),\n",
        "    steps_per_epoch=len(x_train)//batch_size,\n",
        "    validation_data = datagen_val.flow(x_val, y_val, batch_size=batch_size, shuffle=True),\n",
        "    validation_steps = len(x_val)//batch_size,\n",
        "    epochs=12,\n",
        "    callbacks=callbacks\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4ny3aWotugO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5KKoBG_Etug9"
      },
      "source": [
        "## Task 8: Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2EqymPotuhF"
      },
      "source": [
        "model.evaluate(x_val, y_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTUfQc8dtuh2"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn import metrics\n",
        "import seaborn as sns\n",
        "\n",
        "y_true = np.argmax(y_val, 1)\n",
        "y_pred = np.argmax(model.predict(x_val), 1)\n",
        "print(metrics.classification_report(y_true, y_pred))\n",
        "print(\"Classification accuracy: %0.6f\" % metrics.accuracy_score(y_true, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uU-K6vA9tuie"
      },
      "source": [
        "labels = [\"squiggle\", \"narrowband\", \"noise\", \"narrowbanddrd\"]\n",
        "\n",
        "ax= plt.subplot()\n",
        "sns.heatmap(metrics.confusion_matrix(y_true, y_pred, normalize='true'), annot=True, ax = ax, cmap=plt.cm.Blues); #annot=True to annotate cells\n",
        "\n",
        "# labels, title and ticks\n",
        "ax.set_title('Confusion Matrix'); \n",
        "ax.xaxis.set_ticklabels(labels); ax.yaxis.set_ticklabels(labels);"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}