{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Food11.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1xkY298nqsM4"
      },
      "source": [
        "# TASK #1: Load dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DziMVKFtL7jf"
      },
      "source": [
        "https://drive.google.com/drive/folders/1zf9iza_kdlhdZxBQ1OIKesbgy7rD23CH?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gsNWtoyWzhP1"
      },
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/gdrive')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QFLf1y4xqzGl"
      },
      "source": [
        "# TASK #2: IMPORT LIBRARIES/DATASETS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lf_7805PvGgZ"
      },
      "source": [
        "#import the necessary packages\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import PIL\n",
        "import seaborn as sns\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.initializers import glorot_uniform\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from IPython.display import display\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint, LearningRateScheduler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qHz0OelTMNky"
      },
      "source": [
        "#Check path of Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUmPRk_NvrXz"
      },
      "source": [
        "%cd /content/gdrive/My\\ Drive/Food/food11"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WiV9-QvCrA3I"
      },
      "source": [
        "# TASK #3: DATA EXPLORATION AND DATA VISUALIZATION:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_EUHCz30v79"
      },
      "source": [
        "# Check the number of images in training, validation and test dataset\n",
        "\n",
        "train = []\n",
        "valid = []\n",
        "test = []\n",
        "\n",
        "#os.listdir returns the list of files in the folder, in this case image class names\n",
        "for i in os.listdir('./training'):\n",
        "  train_class = os.listdir(os.path.join('training',i))\n",
        "  train.extend(train_class)\n",
        "  valid_class = os.listdir(os.path.join('validation',i))\n",
        "  valid.extend(valid_class)\n",
        "  test_class = os.listdir(os.path.join('evaluation',i))\n",
        "  test.extend(test_class)\n",
        "\n",
        "print('Number of train images : {} \\nNumber of validation images : {} \\nNumber of test images : {}'.format(len(train),len(valid),len(test)))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bw_N3GC2GPi"
      },
      "source": [
        "#Visualize the images in the dataset\n",
        "\n",
        "fig, axs = plt.subplots(11,5, figsize=(32,32))\n",
        "count = 0\n",
        "for i in os.listdir('./training'):\n",
        "  # get the list of images in the particualr class\n",
        "  train_class = os.listdir(os.path.join('training',i))\n",
        "  #plot 5 images per class\n",
        "  for j in range(5):\n",
        "    img = os.path.join('training',i,train_class[j])\n",
        "    \n",
        "    img = PIL.Image.open(img)\n",
        "    axs[count][j].title.set_text(i)\n",
        "    axs[count][j].imshow(img)  \n",
        "  count += 1\n",
        "\n",
        "fig.tight_layout()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BgmZEvwgIzqc"
      },
      "source": [
        "#check the number of images in each class in the training dataset\n",
        "\n",
        "No_images_per_class = []\n",
        "Class_name = []\n",
        "for i in os.listdir('./training'):\n",
        "  train_class = os.listdir(os.path.join('training',i))\n",
        "  No_images_per_class.append(len(train_class))\n",
        "  Class_name.append(i)\n",
        "  print('Number of images in {} = {} \\n'.format(i,len(train_class)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Bimf3qJN0bk"
      },
      "source": [
        "#visualize the number of images in each class in the training dataset\n",
        "\n",
        "fig = plt.figure(figsize=(10,5))\n",
        "plt.bar(Class_name, No_images_per_class,color = sns.color_palette(\"cubehelix\",len(Class_name)))\n",
        "fig.tight_layout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TRCi25WyuZ-T"
      },
      "source": [
        "# TASK #4: PERFORM DATA AUGMENTATION AND CREATE DATA GENERATOR:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7phFxj7xuUP4"
      },
      "source": [
        "#create run-time augmentation on training and test dataset\n",
        "#For training datagenerator,we add normalization ,shear angle, zooming range and horizontal flip\n",
        "train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True)\n",
        "\n",
        "#For test datagenerator, we only normalize the data.\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0gD1o9WpyOwy"
      },
      "source": [
        "#Creating datagenerator for training, validation and test dataset.\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        'training',\n",
        "        target_size=(256, 256),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "        'validation',\n",
        "        target_size=(256, 256),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical')\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "        'evaluation',\n",
        "        target_size=(256, 256),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ser8TL4hx0d1"
      },
      "source": [
        "# TASK #6: BUILD DEEP LEARNING MODEL USING PRE-TRAINED INCEPTIONRESNETV2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DuDXHzHwz3dR"
      },
      "source": [
        "#load the inception resnetv2 model\n",
        "\n",
        "basemodel = InceptionResNetV2(weights = 'imagenet', include_top = False, input_tensor = Input(shape=(256,256,3)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1HLFCO1H05C2"
      },
      "source": [
        "#print the model summary\n",
        "basemodel.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EN_NR37Z07Z-"
      },
      "source": [
        "#Freeze the basemodel weights , so these weights won't change during training\n",
        "basemodel.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utpCBuch5K5j"
      },
      "source": [
        "#Add classifiction head to the model\n",
        "\n",
        "headmodel = basemodel.output\n",
        "headmodel = GlobalAveragePooling2D(name = 'global_average_pool')(headmodel)\n",
        "headmodel = Flatten(name= 'flatten')(headmodel)\n",
        "headmodel = Dense(256, activation = \"relu\", name = 'dense_1')(headmodel)\n",
        "headmodel = Dropout(0.3)(headmodel)\n",
        "headmodel = Dense(128, activation = \"relu\", name = 'dense_2')(headmodel)\n",
        "headmodel = Dropout(0.2)(headmodel)\n",
        "headmodel = Dense(11, activation = 'softmax', name = 'dense_3')(headmodel)\n",
        "\n",
        "model = Model(inputs = basemodel.input, outputs = headmodel)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uc1sTj2aYRu-"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mv5gK4Yjztgt"
      },
      "source": [
        "# TASK #7: COMPILE AND TRAIN DEEP LEARNING MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L02vuv875Uv7"
      },
      "source": [
        "#compile the model\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer= SGD(lr=.01, momentum=.9) , metrics= [\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wNwcURek5YnQ"
      },
      "source": [
        "#using early stopping to exit training if validation loss is not decreasing even after certain epochs (patience)\n",
        "earlystopping = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=20)\n",
        "\n",
        "#save the best model with lower validation loss\n",
        "checkpointer = ModelCheckpoint(filepath=\"weights.hdf5\", verbose=1, save_best_only=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkFyneJU6Dot"
      },
      "source": [
        "history = model.fit(train_generator, steps_per_epoch= train_generator.n // 32, epochs = 100, validation_data= validation_generator, validation_steps= validation_generator.n // 32, callbacks=[checkpointer, earlystopping])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXNYYqTwIJIG"
      },
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train_loss','val_loss'], loc = 'upper right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5XsIk6XQz3fH"
      },
      "source": [
        "# TASK #8: FINE TUNE THE TRAINED MODEL:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8Vg55sU6N7s"
      },
      "source": [
        "#unfreeze the weights in the base model, now these weights will be changed during training\n",
        "\n",
        "basemodel.trainable = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RijFgtp_H3w2"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXb_P5YbI1IA"
      },
      "source": [
        "#using early stopping to exit training if validation loss is not decreasing even after certain epochs (patience)\n",
        "earlystopping = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=20)\n",
        "\n",
        "#save the best model with lower validation loss\n",
        "checkpointer = ModelCheckpoint(filepath=\"weights_fine.hdf5\", verbose=1, save_best_only=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JTIVBL27H7qM"
      },
      "source": [
        "#fine tune the model with very low learning rate\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer= SGD(lr=0.0001, momentum=.9) , metrics= [\"accuracy\"])\n",
        "history = model.fit(train_generator, steps_per_epoch= train_generator.n // 32, epochs = 10, validation_data= validation_generator, validation_steps= validation_generator.n // 32, callbacks=[checkpointer, earlystopping])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bv0u2ZqmFdWn"
      },
      "source": [
        "model.load_weights(\"weights_fine.hdf5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "od4ORdp50W8O"
      },
      "source": [
        "# TASK #9: ASSESS THE PERFORMANCE OF THE TRAINED MODEL:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ox5UpdcIe1L"
      },
      "source": [
        "#Evaluate the performance of the model\n",
        "evaluate = model.evaluate_generator(test_generator, steps = test_generator.n // 32, verbose =1)\n",
        "\n",
        "print('Accuracy Test : {}'.format(evaluate[1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GmXWmLQPOGCc"
      },
      "source": [
        "#assigning label names to the corresponding indexes\n",
        "labels = {0: 'Bread', 1: 'Dairy product', 2: 'Dessert', 3:'Egg', 4: 'Fried food', 5:'Meat',6:'Noodles-Pasta',7:'Rice', 8:'Seafood',9:'Soup',10: 'Vegetable-Fruit'}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ja8K9HDUMvXN"
      },
      "source": [
        "#loading images and their predictions \n",
        "\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
        "import cv2\n",
        "\n",
        "prediction = []\n",
        "original = []\n",
        "image = []\n",
        "count = 0\n",
        "for i in os.listdir('./evaluation'):\n",
        "  for item in os.listdir(os.path.join('./evaluation',i)):\n",
        "    #code to open the image\n",
        "    img= PIL.Image.open(os.path.join('./evaluation',i,item))\n",
        "    #resizing the image to (256,256)\n",
        "    img = img.resize((256,256))\n",
        "    #appending image to the image list\n",
        "    image.append(img)\n",
        "    #converting image to array\n",
        "    img = np.asarray(img, dtype= np.float32)\n",
        "    #normalizing the image\n",
        "    img = img / 255\n",
        "    #reshaping the image in to a 4D array\n",
        "    img = img.reshape(-1,256,256,3)\n",
        "    #making prediction of the model\n",
        "    predict = model.predict(img)\n",
        "    #getting the index corresponding to the highest value in the prediction\n",
        "    predict = np.argmax(predict)\n",
        "    #appending the predicted class to the list\n",
        "    prediction.append(labels[predict])\n",
        "    #appending original class to the list\n",
        "    original.append(i)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJF0bF1xSE10"
      },
      "source": [
        "#Getting the test accuracy \n",
        "score = accuracy_score(original,prediction)\n",
        "print(\"Test Accuracy : {}\".format(score))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uIi_GI-oSG1a"
      },
      "source": [
        "#visualizing the results\n",
        "import random\n",
        "fig=plt.figure(figsize = (100,100))\n",
        "for i in range(20):\n",
        "    j = random.randint(0,len(image))\n",
        "    fig.add_subplot(20,1,i+1)\n",
        "    plt.xlabel(\"Prediction -\" + prediction[j] +\"   Original -\" + original[j])\n",
        "    plt.imshow(image[j])\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XbmWMQcSM0b"
      },
      "source": [
        "#classiication report\n",
        "print(classification_report(np.asarray(original), np.asarray(prediction)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HaXGkGP8OO98"
      },
      "source": [
        "#plotting confusion matrix\n",
        "\n",
        "plt.figure(figsize=(20,20))\n",
        "cm = confusion_matrix(np.asarray(original), np.asarray(prediction))\n",
        "ax = plt.subplot()\n",
        "sns.heatmap(cm, annot = True, ax = ax)\n",
        "\n",
        "ax.set_xlabel('Predicted')\n",
        "ax.set_ylabel('Original')\n",
        "ax.set_title('Confusion_matrix')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XkuhUAIt2tfQ"
      },
      "source": [
        "# TASK #10: VISUALIZING ACTIVATION MAPS THROUGH GRAD-CAM:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nnwOS5PZS8D"
      },
      "source": [
        "def grad_cam(img):\n",
        "\n",
        "  #Covert the image to array of type float32\n",
        "  img = np.asarray(img, dtype= np.float32)\n",
        "\n",
        "  #Reshape the image from (256,256,3) to (1,256,256,3)\n",
        "  img = img.reshape(-1,256,256,3)\n",
        "  img_scaled = img / 255\n",
        "\n",
        "  #Name of the layers we added to the base_model, you can find this in the model summaty\n",
        "  #Every-time you run the model, check the summary, as the name would change or to avoid it \n",
        "  #you can add name to each layer\n",
        "  classification_layers = [\"global_average_pool\",\"dense_1\",\"dense_2\",\"dense_3\"]\n",
        "\n",
        "  #Last convolutional layer in the base mdel, this woun't change as name has been already assigned to it.\n",
        "  final_conv = model.get_layer(\"conv_7b\")\n",
        "\n",
        "  #Create a model with original model input as input and the last conv_layer as the output\n",
        "  final_conv_model = keras.Model(model.inputs, final_conv.output)\n",
        "\n",
        "  #Then,we create the input for classification layer, which is the output of last conv layer\n",
        "  #In our case, output produced by the conv layer is of the shape (1,6,6,1536) \n",
        "  #Since, the classification input needs the features as input, we ignore the batch dimension\n",
        "\n",
        "  classification_input = keras.Input(shape=final_conv.output.shape[1:])\n",
        "\n",
        "  # We iterate through the classification layers, to get the final layer and then, append \n",
        "  #the layer as the output layer to the classification model.\n",
        "  temp = classification_input\n",
        "  for layer in classification_layers:\n",
        "      temp = model.get_layer(layer)(temp)\n",
        "  classification_model = keras.Model(classification_input, temp)\n",
        "\n",
        "\n",
        "  #We use gradient tape to monitor the 'final_conv_output' to retrive the gradients\n",
        "  #corresponding to the predicted class\n",
        "  with tf.GradientTape() as tape:\n",
        "      # Pass the image through the base model and get the feature map \n",
        "      final_conv_output = final_conv_model(img_scaled)\n",
        "\n",
        "      #Assign gradient tape to monitor the conv_output\n",
        "      tape.watch(final_conv_output)\n",
        "      \n",
        "      #Pass the feature map through the classification model and use argmax to get the \n",
        "      #index of the predicted class and then use the index to get the value produced by final\n",
        "      #layer for that class\n",
        "      prediction = classification_model(final_conv_output)\n",
        "      predicted_class = tf.argmax(prediction[0])\n",
        "      predicted_class_value = prediction[:, predicted_class]\n",
        "\n",
        "  #Get the gradient corresponding to the predicted class based on feature map.\n",
        "  #which is of shape (1,6,6,1536)\n",
        "  gradient = tape.gradient(predicted_class_value, final_conv_output)\n",
        "\n",
        "  #Since we need the filter values (1536), we reduce the other dimensions, \n",
        "  #hich would result in a shape of (1536,)\n",
        "  gradient_channels = tf.reduce_mean(gradient, axis=(0, 1, 2))\n",
        "\n",
        "  #We then convert the feature map produced by last conv layer(1,6,6,1536) to (6,6,1536)\n",
        "\n",
        "  final_conv_output = final_conv_output.numpy()[0]\n",
        "\n",
        "  gradient_channels = gradient_channels.numpy()\n",
        "\n",
        "  #We multiply the filters in the feature map produced by final conv layer by the \n",
        "  #filter values that are used to get the predicted class. By doing this we inrease the\n",
        "  #value of areas that helped in making the prediction and lower the vlaue of areas, that \n",
        "  #did not contribute towards the final prediction\n",
        "  for i in range(gradient_channels.shape[-1]):\n",
        "      final_conv_output[:, :, i] *= gradient_channels[i]\n",
        "\n",
        "  #We take the mean accross the channels to get the feature map\n",
        "  heatmap = np.mean(final_conv_output, axis=-1)\n",
        "\n",
        "  #Normalizing the heat map between 0 and 1, to visualize it\n",
        "  heatmap_normalized = np.maximum(heatmap, 0) / np.max(heatmap)\n",
        "\n",
        "  # Rescaling and converting the type to int\n",
        "  heatmap = np.uint8(255 * heatmap_normalized )\n",
        "\n",
        "  # Create the colormap\n",
        "  color_map = plt.cm.get_cmap('jet')\n",
        "\n",
        "  # get only the rb features from the heatmap\n",
        "  color_map = color_map(np.arange(256))[:, :3]\n",
        "  heatmap = color_map[heatmap]\n",
        "\n",
        "  #convert the array to image, resize the image and then convert to array\n",
        "  heatmap = keras.preprocessing.image.array_to_img(heatmap)\n",
        "  heatmap = heatmap.resize((256, 256))\n",
        "  heatmap = np.asarray(heatmap, dtype = np.float32)\n",
        "\n",
        "  # Add the heatmap o top of the original image\n",
        "  final_img = heatmap * 0.8 + img[0]\n",
        "  final_img = keras.preprocessing.image.array_to_img(final_img)\n",
        "\n",
        "  return final_img, heatmap_normalized\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1CFXeOvd0Fe"
      },
      "source": [
        "#Visualize the images in the dataset\n",
        "import random\n",
        "fig, axs = plt.subplots(11,3, figsize=(32,32))\n",
        "count = 0\n",
        "for _ in range(11):\n",
        "  i = random.randint(0,len(image))\n",
        "  gradcam, heatmap = grad_cam(image[i])\n",
        "  axs[count][0].title.set_text(\"Original -\" + original[i])\n",
        "  axs[count][0].imshow(image[i])\n",
        "  axs[count][1].title.set_text(\"Prediction -\" + prediction[i]) \n",
        "  axs[count][1].matshow(heatmap)\n",
        "  axs[count][2].title.set_text(\"Heatmap\") \n",
        "  axs[count][2].imshow(gradcam)  \n",
        "  count += 1\n",
        "\n",
        "fig.tight_layout()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}